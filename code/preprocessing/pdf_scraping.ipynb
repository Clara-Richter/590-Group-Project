{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DaIJsQiSnPi"
      },
      "source": [
        "## This notebook aims to scrape all historical race results PDFs of AQU, BEL and SAR in 2019. \n",
        "The PDFs are store in the shared Google drive: https://drive.google.com/drive/u/0/folders/1cND78Y9CmdMm5B_v0tWPFGSolIG5q-6h. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "id": "hR6woO7vaj3e",
        "outputId": "c17ba341-81d1-4cf2-87e3-a398c2d39e09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.7.5-py3-none-any.whl (40 kB)\n",
            "\u001b[K     |████████████████████████████████| 40 kB 3.3 MB/s \n",
            "\u001b[?25hCollecting Pillow>=9.1\n",
            "  Downloading Pillow-9.3.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 6.6 MB/s \n",
            "\u001b[?25hCollecting Wand>=0.6.10\n",
            "  Downloading Wand-0.6.10-py2.py3-none-any.whl (142 kB)\n",
            "\u001b[K     |████████████████████████████████| 142 kB 51.6 MB/s \n",
            "\u001b[?25hCollecting pdfminer.six==20220524\n",
            "  Downloading pdfminer.six-20220524-py3-none-any.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 29.4 MB/s \n",
            "\u001b[?25hCollecting cryptography>=36.0.0\n",
            "  Downloading cryptography-38.0.3-cp36-abi3-manylinux_2_24_x86_64.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 29.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from pdfminer.six==20220524->pdfplumber) (2.1.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=36.0.0->pdfminer.six==20220524->pdfplumber) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20220524->pdfplumber) (2.21)\n",
            "Installing collected packages: cryptography, Wand, Pillow, pdfminer.six, pdfplumber\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "Successfully installed Pillow-9.3.0 Wand-0.6.10 cryptography-38.0.3 pdfminer.six-20220524 pdfplumber-0.7.5\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#!pip install pdfplumber\n",
        "\n",
        "import pdfplumber\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "IGFEfVPXbQvA"
      },
      "outputs": [],
      "source": [
        "drive_path = '/content/drive/Shareddrives/ANLY590_GROUP_4_PROJECT'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VKmqZLzbMfq",
        "outputId": "993e98d8-fe6f-4279-9724-57b0ebee8d9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/Shareddrives/ANLY590_GROUP_4_PROJECT/data/historical_result_pdf/BEL-BELMONT PARK/05-12-2019-3.pdf something's wrong\n",
            "[['BEL-BELMONT PARK', 'May12,2019', '3', '20Apr194LRL6', '3', 'Slimey(Carmouche,Kendrick)', '118', 'Lf', '2', '3', '21/2', '---', '39', '11/2', '131/2', '4w,edgecl,purseonly'], ['BEL-BELMONT PARK', 'May12,2019', '3', '31Mar197AQU6', '1', 'RagtimeSuzy(Castellano,Javier)', '123', 'L', '1', '5', '461/2', '21', '---', '36', '211/4', '2.30', '5wupper,ranon'], ['BEL-BELMONT PARK', 'May12,2019', '3', '2May197BEL6', '8', 'PartyintheSand(Rosario,Joel)', '123', 'L', '5', '1', '5', '41/2', '---', '411', '311/2', '4.60', '6wupper,belatedly'], ['BEL-BELMONT PARK', 'May12,2019', '3', '30Dec186AQU3', '7', 'Athwaaq(Lezcano,Jose)', '123', 'L', '4', '4', '111/2', '11/2', '---', '2Head', '4353/4', '0.60', 'coaxedst,weakened'], ['BEL-BELMONT PARK', 'May12,2019', '3', '13Apr192AQU6', '6', 'AweHoney(Cancel,Eric)', '118', 'L', '3', '2', '311/2', '5', '---', '5', '5', '9.40', 'chased2-3w,faltered']]\n",
            "['BEL-BELMONT PARK', 'May12,2019', '3', '20Apr194LRL6', '3', 'Slimey(Carmouche,Kendrick)', '118', 'Lf', '2', '3', '21/2', '---', '39', '11/2', '131/2', '4w,edgecl,purseonly']\n",
            "/content/drive/Shareddrives/ANLY590_GROUP_4_PROJECT/data/historical_result_pdf/AQU-AQUEDUCT/11-10-2019-5.pdf something's wrong\n",
            "[['AQU-AQUEDUCT', 'November10,2019', '5', '27Sep198BEL1', '6', 'Valmont(Franco,Manuel)', '120', 'L', '6', '4', '31/2', '3Head', '---', '21', '1Head', '8.90', 'bumpedst,heldon'], ['AQU-AQUEDUCT', 'November10,2019', '5', '18Oct196BEL7', '8', 'ThreeOutlaws(Ortiz,Jr.,Irad)', '118', 'Lb', '7', '8', '91', '92', '---', '51/2', '23/4', '2.35', 'brushedst,gdfinish'], ['AQU-AQUEDUCT', 'November10,2019', '5', '18Oct191LRL4', '14', 'Brockmoninoff(Cancel,Eric)', '120', 'Lf', '12', '1', '11', '11', '---', '12', '331/4', '26.75', 'inhand2p,caughtlte'], ['AQU-AQUEDUCT', 'November10,2019', '5', '16Oct192BEL5', '12', 'Coolboy(Martinez,Joey)', '114', 'L', '10', '5', '41/2', '211/2', '---', '32', '41/2', '32.00', '3w1/4,bid,wkndlate'], ['AQU-AQUEDUCT', 'November10,2019', '5', '30Aug193SAR1', '1', 'WildWilliam(McCarthy,Trevor)', '120', 'Lb', '1', '6', '611/2', '51/2', '---', '61', '51/2', '12.60', 'bobbledst,outkicked'], ['AQU-AQUEDUCT', 'November10,2019', '5', '18Oct196BEL6', '5', 'PreferredOutcome(Lezcano,Jose)', '122', 'L', '5', '10', '11Head', '101/2', '---', '91/2', '621/2', '6.30', '3-4wuppr,bytired'], ['AQU-AQUEDUCT', 'November10,2019', '5', '11Sep192BEL3', '4', 'Elenzee(Rosario,Joel)', '122', 'Lb', '4', '7', '721/2', '71', '---', '71/2', '7Nose', '4.20', 'veerinst,norally'], ['AQU-AQUEDUCT', 'November10,2019', '5', '18Oct196BEL12', '13', 'Alphastest(Diaz,Jr.,Hector)', '118', 'L', '11', '3', '2Head', '411/2', '---', '41/2', '8Head', '67.50', 'chased3-2w,weakened'], ['AQU-AQUEDUCT', 'November10,2019', '5', '18Oct196BEL9', '10', 'StarryMessenger(Camacho,Jr.,Samuel)', '120', 'Ly', '8', '2', '51/2', '611/2', '---', '81', '911/2', '105.25', 'chased2-3w,weakened'], ['AQU-AQUEDUCT', 'November10,2019', '5', '3Aug1911SAR8', '11', 'JacktheCat(Carmouche,Kendrick)', '119', 'Lb', '9', '9', '81/2', '---', '81/2', '1021/2', '1041/2', 'chased3-4w,weakened'], ['AQU-AQUEDUCT', 'November10,2019', '5', '18Sep196BEL3', '2', 'CrackShot(Ortiz,Jose)', '120', 'Lb', '2', '11', '12', '11Head', '---', '1131/2', '1193/4', '2.40', 'bumped,pinchedst'], ['AQU-AQUEDUCT', 'November10,2019', '5', '7Aug197SAR9', '3', 'Bydawnsearlylight(Carroll,Declan)', '115', 'Lb', '3', '12', '1011/2', '12', '---', '12', '12', '89.75', 'steady,squeezedst']]\n",
            "['AQU-AQUEDUCT', 'November10,2019', '5', '3Aug1911SAR8', '11', 'JacktheCat(Carmouche,Kendrick)', '119', 'Lb', '9', '9', '81/2', '---', '81/2', '1021/2', '1041/2', 'chased3-4w,weakened']\n"
          ]
        }
      ],
      "source": [
        "path1 = drive_path + \"/data/historical_result_pdf\"\n",
        "\n",
        "# Get all the data under the dir.\n",
        "file_name_list = os.listdir(path1)\n",
        "\n",
        "# Column names.\n",
        "title = [\"Track\",\"Date\",\"Race\",\"LastRaced\",\"Pgm\",\"HorseName(Jockey)\",\"Wgt\",\"M/E\",\"PP\",\"Start\",\"0.25\",\"0.5\",\"0.75\",\"Str\",\"Fin\",\"Odds\",\"Comments\"]\n",
        "\n",
        "data_list=[]\n",
        "\n",
        "for pa in file_name_list:\n",
        "\n",
        "    # Get different track names.\n",
        "    path2 = drive_path + \"/data/historical_result_pdf/{}\".format(pa)\n",
        "    file_name_list2 = os.listdir(path2)\n",
        "\n",
        "    for p in file_name_list2:\n",
        "      \n",
        "        # Access single pdf file.\n",
        "        path = drive_path + \"/data/historical_result_pdf/{}/{}\".format(pa,p)\n",
        "        pdf_mt = pdfplumber.open(path)\n",
        "        page = pdf_mt.pages[0]\n",
        "\n",
        "        # Extract the text.\n",
        "        text_data=page.extract_text()\n",
        "        text_data=list(text_data.split('\\n'))\n",
        "        \n",
        "        # A indicator for teh lines to keep.\n",
        "        a=0\n",
        "        da=[]\n",
        "\n",
        "        # Find the lines to keep.\n",
        "        for data in text_data:\n",
        "            if data.find(\"FractionalTimes:\")!=-1:\n",
        "                a = 0\n",
        "            if a == 1:\n",
        "                da.append(list(data.split(' ')))\n",
        "            if data.find(\"LastRaced Pgm HorseName(Jockey) WgtM/E PP Start\")!=-1:\n",
        "                a = 1\n",
        "\n",
        "        # Keep the race and date of the pdf.\n",
        "        date = list(text_data[0].split('-'))\n",
        "        race = date[-1].replace(\"Race\",'')\n",
        "        date = date[1]\n",
        "\n",
        "        # Partition the data\n",
        "        list2=['»','½','¶(cid:4)']\n",
        "        for i in range(len(da)):\n",
        "            da[i][-2]=da[i][-2].replace('*','')\n",
        "            if da[i][3].find(\"L\")!=-1 or da[i][3].find(\"b\") != -1:\n",
        "                for f in list2:\n",
        "                    if da[i][3].find(f) != -1:\n",
        "                        b = list(da[i][3].split(f))\n",
        "                        da[i][3] = b[0]\n",
        "                        da[i].insert(4, b[-1])\n",
        "            for f in list2:\n",
        "                da[i][3] = da[i][3].replace(f, '')\n",
        "            if len(da[i])==13:\n",
        "                da[i].insert(9,'---')\n",
        "            if len(da[i])==12:\n",
        "                da[i].insert(8,'---')\n",
        "            da[i].insert(0, race)\n",
        "            da[i].insert(0, date)\n",
        "            da[i].insert(0, pa)\n",
        "            \n",
        "        for data in da:\n",
        "            if len(data) != 17:\n",
        "                print(path, \"something's wrong\")\n",
        "                print(da)\n",
        "                print(data)\n",
        "                continue\n",
        "            data_list.append(data)\n",
        "\n",
        "# Create the dataframe.\n",
        "data = np.array(data_list).transpose()\n",
        "dict2 = {}\n",
        "for i in range(len(data)):\n",
        "    dict2[title[i]]=data[i]\n",
        "\n",
        "data = pd.DataFrame(dict2)\n",
        "data.to_csv(drive_path + \"/data/raw/historical_results.csv\",index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
